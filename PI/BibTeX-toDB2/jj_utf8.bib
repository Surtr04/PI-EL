@string{ um="Universidade do Minho" }
@string{ umdi="Universidade do Minho, Departamento de Informática" }

@article{ velharia1,
  author = {J.J. Almeida and A. Filipe},
  title = {Descrição de um Núcleo Gráfico e Aplicação em {CAD}},
  journal = {Revista de Informática},
  note = {(KGUM - kernel gráfico U.Minho)},
  number = 1,
  volume = 6,
  year = 1987,
}

@article{ velharia2,
  author = {C. Ferreira and F. Ferreira and F. Martins and  J.J. Almeida and L. Barbosa},
  title = {Sistemas de Programação Modular},
  journal = {Revista de Informática},
  number = 6,
  volume = 9,
  year = 1988,
}

@inproceedings{graminteractivas1990,
  author={F. Mário Martins and J.J. Almeida and P.R. Henriques},
  title = {Mecanismos para Especificação e Prototipagem de Interfaces
    Utilizador-Sistema},
  note = {(Gramáticas Interactivas guardadas)},
  booktitle={3$º$ Encontro Português de Computação Gráfica},
  address="Coimbra",
  year = 1990,
}

@techreport{tlc89,
 author={J.J. Almeida and J.B. Barros},
 title = {Teoria das Linguagens },
 institution = umdi,
 type = "Texto didáctico",
 year = 1988,
 keyword = "compiladores",
}

@techreport{estruturasdedados90,
 author={J.B. Barros and J.J. Almeida},
 title = {Estruturas de Dados},
 institution = umdi,
 type = "Texto didáctico",
 year = 1990,
 keyword = "algoritmos",
}

@techreport{Camila,
  author ={{projecto Camila}},
  editor ={L.S. Barbosa and J.J. Almeida and J.N. Oliveira and Luís Neves},
  title = "\textsc{Camila} - A Platform for Software Mathematical Development",
  url="http://camila.di.uminho.pt",
  type="(Páginas do projecto)",
  institution = umdi,
  year=1998,
  keyword = "FS",
}

@techreport{Natura,
  author ={J.J. Almeida},
  title = "{Natura} - Natural language processing",
  url="http://natura.di.uminho.pt/",
  type="(Páginas do projecto)",
  note="\url{http://natura.di.uminho.pt/}",
  institution = umdi,
  keyword = "PLN",
  year = 1997,
}

@techreport{PDavid,
  author = "{projecto David}",
  editor ={J.C. Ramalho and J.J. Almeida and P.R. Henriques},
  title = "David -- Processamento estruturado de documentos",
  url="http://www.di.uminho.pt/~jcr/projectos/david/princ.html",
  note="\url{http://www.di.uminho.pt/~jcr/projectos/david/princ.html}",
  type="(Páginas do projecto)",
  institution = umdi,
  keyword = "FS,SGML",
  year = 1998,
}

@misc{nllex,
  type={tool},
  author ={J.J. Almeida},
  title = "NLlex -- Natural Language LEX",
  url="http://natura.di.uminho.pt/~jj/pln/pln.html#nllex",
  keyword = "lexical analysis, Natura,lex",
  year = 1996,
}

@misc{jspell,
  type = {tool},
  author ={J.J. Almeida and Ulisses Pinto},
  title = "Jspell a module for morphological analyser for natural language",
  url="http://natura.di.uminho.pt/~jj/pln/pln.html#jspell",
  keyword = "lexical analysis, Natura,morphology",
  year = 1997,
}

@techreport{jspell1,
   author = "J.J. Almeida and Ulisses Pinto",
   title = "Manual de Utilizador do {JSpell}",
   year = 1994,
   type = "Manual",
   month = "Jul",
   institution = umdi,
   keyword = "morphology, lexical analysis,jspell",
   abstract = {},
   url = "http://natura.di.uminho.pt/~jj/pln/jspellman.ps.gz",
}

@inproceedings{Almeida94b,
   author = "J.J. Almeida",
   title = "{GPC} -- a Tool for higher-order grammar specification",
   booktitle = "Actas del X Congreso de Lenguajes Naturales e Leanguajes Formales, Sevilla",
   year = 1994,
   url = "http://natura.di.uminho.pt/~jj/pln/yalg3.ps.gz",
   editor="Carlos Martin Vide",
 keyword ="DCG,grammar",
}

@inproceedings{Almeida95a,
   author = "J.J. Almeida",
   title = "{YaLG} -- extending {DCG} for natural language processing",
   booktitle = "Actas del XI Congreso de Lenguajes Naturales e Leanguajes Formales, Tortosa",
   year = 1995,
   pages = "621--628",
   editor="Carlos Martin Vide",
   url = "http://natura.di.uminho.pt/~jj/pln/yalg.ps.gz",
 keyword ="jspell,morphology,PLN,DCG,nllex",
}

@inproceedings{Almeida94c,
   author = "J.J. Almeida and Ulisses Pinto",
   title = "Jspell -- um módulo para análise léxica genérica de linguagem natural",
   booktitle = "Actas do X Encontro da Associação Portuguesa de Linguística",
 address={Évora 1994},
   pages = "1--15",
   year = 1995,
   url = "http://natura.di.uminho.pt/~jj/pln/jspell1.ps.gz",
 keyword ="jspell,morphology,PLN,perl",
}

@inproceedings{Almeida94a,
   author = "J.J. Almeida",
   title = "Documents in an Informatic Academic environment",
   booktitle = "Congresso Nacional de Bibliotecários, Arquivistas e
Documentalistas",
   address = "Lisboa",
   year = 1994,
 keyword ="librarian studies,WWW,WAIS,IR",
}

@techreport{jj95,
   author = "J.J. Almeida",
   title = "{NLlex} -- a tool to generate lexical analysers for natural language",
   institution = umdi,
   year   = 1995,
   number = "UM-DI-95.04",
   url = "http://natura.di.uminho.pt/~jj/pln/nllex.ps.gz",
 keyword ="jspell,morphology,lex,PLN,nllex",
}

@techreport{Barbosa95,
 author = "L.S. Barbosa and J.J. Almeida",
 title  = "System Prototyping in \textsc{Camila}",
 year = 1995,
 number = "DI-CAM-95:11:1",
 institution="University of Minho",
 note = "Lecture notes for the System Design Course,
         Computer System Engineering, University of Bristol",
 url="http://www.di.uminho.pt/~lsb/pub_camila/LNcam.ps.gz",
 keyword ="Camila, formal specification",
}

@techreport{Barbosa95a,
 author = "L.S. Barbosa and J.J. Almeida",
 title  = "\textsc{Camila}: A reference Manual",
 year = 1995,
 number = "DI-CAM-95:11:2",
 institution="University of Minho",
 url="http://www.di.uminho.pt/~lsb/pub_camila/RMcam.ps.gz",
 keyword ="Camila",
}

@techreport{BA97a,
  keyword = "Formal Methods, Prototyping, Camila",
  author = "L.S. Barbosa and J.J. Almeida",
  title = "Systems Prototyping in \textsc{Camila}",
  type = "{Lecture Notes for the Bristol Course  (1st ed.  1995)}",
  year = 1998,
  institution = "DI (U. Minho)",
  number = "DI-CAM-95:11:1:v98"
  }

@techreport{Barbosa95b,
   author = "L.S. Barbosa and J.J. Almeida",
   title = "Growing Up With \textsc{Camila}",
   institution =   umdi,
   year   = 1995,
   number = "DI-CAM-95:7:1",
   url = "http://www.di.uminho.pt/~lsb/pub_camila/romantic.ps.gz",
 keyword ="Camila, formal specification, didatics",
}

@inproceedings{Ramalho95,
   author = "J.C. Ramalho and J.J. Almeida and P.R. Henriques",
   title = "Algebraic Specification of Documents",
   booktitle = "TWLT10 - Algebraic Methods in Language Processing",
   year = 1995,
   month = "6--8 Dec.",
   editor = "A. Nijholt and G. Scollo and R. Steetskamp",
   address = "Twente University, Netherlands",
   note = "AMiLP'95",
   series = "Twente Workshop on Language Technology",
   url="http://natura.di.uminho.pt/~jj/bib/amilp95.ps.gz",
   docpage="http://www.di.uminho.pt/~jcr/projectos/david/ARTIGOS/AMiLP95/amilp95.html",
   pages = "55--64",
   keyword ="PDavid, Camila, SGML",
}

@inproceedings{Almeida96a,
   author = "J.J. Almeida",
   title = "Especificação e tratamento de Dicionários",
   booktitle = "Actas do XI Encontro da Associação Portuguesa de Linguística",
   address={Lisboa 1995},
   year = 1996,
   volume=2,
   url = "http://natura.di.uminho.pt/~jj/pln/etdic.ps.gz",
   keyword ="perl,morphology,lexical analysis, dictionary",
}

@inproceedings{Ulisses96,
   author = "Ulisses Pinto and J.J. Almeida",
   title = "Tratamento automático de termos compostos",
   booktitle = "Actas do XI Encontro da Associação Portuguesa de Linguística",
   address= "Lisboa 1995",
   volume=2,
   year = 1996,
   url = "http://natura.di.uminho.pt/~jj/pln/ptc.ps.gz",
   keyword = "jspell,morphology,lexical analysis, PLN",
}

@inproceedings{Almeida96b,
   author = "J.J. Almeida and J.B. Barros",
   title = "{YaLG} a tool for higher-order grammar specification",
   booktitle = " II International Conference on Mathematical Linguistics, Tarragona, Spain",
   year = 1996,
   url="http://natura.di.uminho.pt/~jj/pln/yalg2.ps.gz",
   keyword ="yalg,DCG,RS",
}

@article{jj96,
   author = "J.J. Almeida",
   title = "{NLlex} -- a tool to generate lexical analysers for natural language",
   year   = 1996,
   month = "Sep",
   volume = "19",
   pages = "81--90",
  journal =    {Procesamiento del Lenguaje Natural},
   publisher="Sociedade Española para el Procesamiento del Lenguaje Natural",
   keyword ="jspell,morphology,lex,PLN,nllex",
   url= "http://natura.di.uminho.pt/~jj/pln/nllex2.ps.gz",
}

@techreport{Almeida96c,
   author = "J.J. Almeida and J.C. Ramalho",
   title = "From {BiBTeX} to {HTML} semantic nets",
   institution =   umdi,
   year   = 1996,
   number = "DI-DAV-96:1:1",
   docpage = "http://natura.di.uminho.pt/~jcr/bib/dbib.html",
 keyword ="PDavid, bibtex, librarian studies,html",
}

@inproceedings{Ramalho96,
  author = "J.C. Ramalho and J.J. Almeida and P.R. Henriques",
  title = "Document Semantics: two approaches",
  booktitle = "Celebrating a Decade of SGML",
  year = 1996,
  month = "Nov.",
  address = "Boston, USA",
  note = "SGML'96 Conference",
  editor = "Graphic Communications Association",
  publisher = "ArborText",
  pages = "473--483",
 docpage="http://natura.di.uminho.pt/~jcr/projectos/david/COMS/sgml96/sgml96.html",
  keyword ="PDavid, Camila, SGML,AG,FS",
}

@InProceedings{SGML97,
  author = "J.C. Ramalho and J.G. Rocha and J.J. Almeida and P.R. Henriques",
  title = "SGML Documents: where does quality go?",
  booktitle = "SGML/XML'97 Conference",
  year =  1997,
  address = "Washington D.C. - USA",
  month =  "Dec.",
  keyword = "PDavid, SGML, Semantics",
}

@inproceedings{Almeida98,
   author = "J.J. Almeida",
   title = "Programação de dicionários",
   booktitle= "Actas do XIII Encontro da Associação Portuguesa de Linguística",
   year=1998,
   pages="21--28",
   volume= "1",
   address = "Lisboa 1997",
   keyword ="perl,morphology,dictionary,parser",
   url= "http://natura.di.uminho.pt/~jj/bib/progDic.ps.gz",
}

@inproceedings{Reis98,
   author = "Ricardo Reis and J.J. Almeida",
   title = "Etiquetador morfo-sintáctico para o Português",
   booktitle= "Actas do XIII Encontro da Associação Portuguesa de Linguística",
   address = "Lisboa 1997",
   year=1998,
   keyword ="tagger, PLN",
   url= "http://natura.di.uminho.pt/~jj/bib/etiquetador2.ps.gz",
}

@inproceedings{ABNO97a,
   title = "\textsc{Camila}: Formal Software Engineering Supported by Functional Programming",
   author = "J.J. Almeida and Barbosa, L.S. and Neves, F.L. and Oliveira, J.N.",
   booktitle = "Proc. II Conf. Latino Americana de Programaci\'on Funcional ({CLaPF97})",
   editor = "De Giusti, A. and Diaz, J. and Pesado, P.",
   year = 1997,
   month = "October",
   address = "La Plata, Argentina",
   pages = "1343--1358",
   keyword ="Camila, formal specification",
   url = "http://camila.di.uminho.pt/camila-doc/CLaPF97.ps.gz",
}

@inproceedings{ABNO97b,
   title = "\textsc{Camila}: Prototyping and Refinement of Constructive Specifications",
   author = "J.J. Almeida and Barbosa, L.S. and Neves, F.L. and Oliveira, J.N.",
   booktitle = "6th International Conference on Algebraic Methods and Software Technology ({AMAST'97})",
   editor = "Johnson, M.",
   year = 1997,
   month = "December",
   address = "Sydney, Australia",
   publisher = "Springer Lect. Notes Comp. Sci. (1349)",
   pages = "554--559",
   keyword ="Camila, formal specification",
}


@inproceedings{AH97,
   title = "Dynamic Dictionary = cooperative information sources",
   author = "J.J. Almeida and P.R. Henriques",
   year = 1998,
   address = "Australia",
   url = "http://natura.di.uminho.pt/~jj/bib/agentes97.ps.gz",
   keyword ="dictionary, Agentes",
   booktitle = "Proc. II Conference on Knowledge-based Intelligent Electronic Systems ({Kes98})",
   month = "April",
}

@inproceedings{museums98,
 author={J.G. Rocha and M.R. Henriques and J.C. Ramalho and J.J. Almeida 
    and J.L.  Faria and P.R. Henriques},
 title={Adapting Museum Structures for the Web: No Changes Needed!},
 booktitle = "Museums and the Web 1998",
 note = "Toronto - Canadá",
 year= 1998,
}

@inproceedings{ABBN98,
   author = "Almeida, J.J. and Barbosa, L.S. and Barros, J.B. and
             Neves, L.F.",
   title = "On The Development of \textsc{Camila}",
   booktitle = "Workshop on Research Themes on Functional Programming",
   year = 1998,
   month = "18 Sep.",
   editor = "L.S. Barbosa and J.A. Saraiva",
   publisher = "Proc. 3rd Summer School on Advan. Funct. Prog., Braga"
}

@article{Ramalho98,
   author = "J.C. Ramalho and J.J. Almeida and P.R. Henriques",
   title = "Algebraic specification of documents",
   year = 1998,
   volume = "199",
   pages = "231--247",
   journal = "Theoretical Computer Science",
   url="http://natura.di.uminho.pt/~jj/bib/amilp95.ps.gz",
   docpage="http://www.di.uminho.pt/~jcr/projectos/david/ARTIGOS/AMiLP95/amilp95.html",
   keyword ="PDavid, Camila, SGML",
}

@inproceedings{Gis99,
  author = "Jorge Rocha and Ana Silva and Ricardo Henriques and J.J. Almeida and Pedro Henriques",
  title={Formal Methods for {GI} Systems Development},
  booktitle = "Conferência da Association of Geographic Information
Laboratories for Europe (AGILE)",
  address="Roma",
  year=1999,
 keyword="GIS",
}

@inproceedings{RPA99,
  author={Jorge Rocha and Tiago Pedroso and J.J. Almeida},
  title ={{MAPit} - A tool set for automatically generation of {HTML} Maps},
  booktitle = "Conferência da Association of Geographic Information
Laboratories for Europe (AGILE)",
  address="Roma",
  year=1999,
 keyword="GIS, XML, mapit",
}

@inproceedings{RSea99,
  author = {Jorge Gustavo Rocha and Ana Silva and J.J. Almeida and Mario Ricardo Henriques and Pedro Rangel Henriques},
  title= {Sobre a Utilização de Metodologias Formais no Desenvolvimento de
{SIG}},
  booktitle = {GISBRASIL'99, Salvador},
  year=1999,
 keyword="GIS",
}

@inproceedings{xmldt99,
  author = { J.J. Almeida and José Carlos Ramalho},
  title = {{XML::DT} a Perl Down-Translation module},
  booktitle = "XML-Europe'99, Granada - Espanha",
  month = "May",
  year=  1999,
 keyword="XML, perl",
}

@article{RRAH99,
 author={J.C. Ramalho and J.G. Rocha and J.J. Almeida and P.R. Henriques},
 title = {SGML documents: Where does quality go?},
 journal={Markup Languages: theory and practice},
 Volume ="1",
 pages = "75--90",
 publisher="MIT Press",
 year= 1999,
 keyword="SGML",
}

@inproceedings{Barbosa2000,
   author = "L.S. Barbosa and J.B. Barros and J.J. Almeida",
   title = "Polytypic Recursion Patterns",
   year = 2000,
   month = "May",
   booktitle = "{SBLP'2000} (to appear as a ENTCS volume)",
   address = "{UFP}, Recife, Brasil",
   keyword="FS, Camila",
}

@inproceedings{jj2001x,
   author = "J.J. Almeida",
   title = "Smallbook -- comando para produção de livros em pequena escala",
   year = 2000,
   pages = "445--450",
   booktitle = "Actas da II Conferência Internacional de Tecnologias de
Informação e Comunicação na Educação",
   address="Braga",
   keyword="publishing, latex, smallbook",
}

@article{speaker:sepln2001,
 author={J.J. Almeida and A. M. Simões},
 title = {Text to speech -- a rewriting system approach},
  journal =    {Procesamiento del Lenguaje Natural},
 address="Sevilha",
 volume ="27",
 pages = "247--255",
 publisher="Sociedade Española para el Procesamiento del Lenguaje Natural",
 month="Sep.",
 year= 2001,
 keyword="TTS,RS,fonética",
}

@inproceedings{mp2001,
 author= {J.J. Almeida and  J. Gustavo Rocha and  P. Rangel Henriques and
    Sónia Moreira and Alberto Simões}, 
 title = {{Museu da Pessoa} -- Arquitectura} ,
 booktitle = {Congresso Nacional de Bibliotecários, Arquivistas e
    Documentalistas},
 address = {Porto}, 
 url = "http://natura.di.uminho.pt/~jj/bib/museuDaPessoa2001.ps.gz",
 month = "Maio",
 year= 2001,
}

@inproceedings{alfarrabio2001,
 author= {J.J. Almeida and P. Rangel Henriques and J. Gustavo Rocha and  
    Alberto Simões}, 
 title = {Alfarrábio: Adding value to an Heterogeneous Site Collection} ,
 booktitle = {Congresso Nacional de Bibliotecários, Arquivistas e
    Documentalistas},
 address = {Porto}, 
 url = "http://natura.di.uminho.pt/~jj/bib/alfarrabio2001.ps.gz",
 month = "Maio",
 year= 2001,
}

@inproceedings{freq2002,
 author= {Paulo A. Rocha and Alberto M. Simões and J.J. Almeida},
 title={ Cálculo de frequências de
palavras para entradas de dicionários através do uso conjunto de analisadores
morfológicos, taggers e corpora},
 booktitle={Actas do XVII Encontro da Associação Portuguesa de Linguística},
 address={Lisboa 2001},
 pages="407--418",
 year= 2002,
 url ="http://natura.di.uminho.pt/~jj/bib/apl:freqnormpt.ps.gz",
 abstract = {Apresentamos neste documento uma possível abordagem à
                extracção de frequências de palavras a partir de
                corpora, baseada numa utilização cooperativa de várias
                ferramentas de Processamento de Linguagem Natural.},
}

@inproceedings{jspell2002,
 author= {Alberto M. Simões and J.J. Almeida},
 title={ Jspell.pm -- um módulo de análise morfológica
para uso em processamento de linguagem natural},
 booktitle={Actas do XVII Encontro da Associação Portuguesa de Linguística},
 address={Lisboa 2001},
 pages="485--495",
 abstract = {Neste documento é nosso propósito apresentar as
                características presentes no analisador morfológico
                jspell e quais as suas consequências ao nível de
                aplicações de processamento de linguagem natural. Como
                ferramenta que é frequentemente integrada em software
                mais específico, apresentamos um módulo Perl
                desenvolvido com o objectivo de facilitar a interligação
                do analisador morfológico com pequenas aplicações
                desenvolvidas em linguagens de scripting. Devido à
                constante necessidade de melhoramento de dicionários, e
                em particular dos analisadores morfológicos, discutimos
                as propriedades que estes devem conter para facilitar o
                seu processamento e enriquecimento automático.},
 year= 2002,
}

@inproceedings{dag2002,
 author= {Alberto M. Simões and J.J. Almeida and Pedro R. Henriques},
 title={Directory Attribute Grammars},
 booktitle={VI Simpósio Brasileiro de Linguagens de Programação},
 pages = {297--308},
 address = {Rio de Janeiro, Brasil},
 year= 2002,
}

@inproceedings{elpub2002,
 author= {Alberto M. Simões and J.J. Almeida},
 title={Library::* -- a toolkit for digital libraries},
 booktitle={Elpub 2002 -- International Conference on Electronic Publishing},
 address = {Karlov Vary, República Checa},
 month="Nov.",
 pages = {203--211},
 year= 2002,
 isbn = "3-89700-357-0",
 abstract = {
  In last years the amount of digital documents has increased
  dramatically. Unfortunately the same did not occur with the
  structure and organization of the information. Traditionally we
  built a digital library using a catalog with documents'
  meta-information including a conceptual classification and an
  ontology of concepts.
  
  In this document we present a set of modules to help in the task of
  building and maintaining a digital library. It includes a module to
  work with ontologies, a set of modules to handle specific catalog
  formats (like Bib\TeX), a module to define new catalog formats
  and a tool to integrate ontologies and multi-format
  catalogs in a web browse-able knowledge-base.
 }
}

@article{parguess2002,
 author= {J.J. Almeida and Alberto M. Simões and J. Alves de Castro},
 title={Grabbing parallel corpora from the web},
 publisher="Sociedade Española para el Procesamiento del Lenguaje Natural",
  journal =    {Procesamiento del Lenguaje Natural},
 volume ="29",
 pages = "13--20",
 month="Sep.",
 year= 2002,
  abstract = {
  Multilingual resources  are useful for linguistic studies, translation, 
and many other tasks. Unfortunately, these resources are difficult to obtain
and organize. 
  In this document we describe a set of tools designed to help in the
task of mining bilingual resources from the web, from a specific site, 
from a file system, from a list of URLs, or from a translation memory.
  As a design goal we intend to build tools that can be used both
cooperatively (in pipeline)  and also in a independent way.  }
}

@Article{cP,
  author = "Alberto Manuel Simões",
  title = "Cooking Perl with flex",
  journal = "The Perl Review",
  year = "2002",
  volume = "0",
  number = "3", 
  month = "May",
  abstract = {

     There are a lot of tools for parser generation using Perl. As we
     know, Perl has flexible data structures which makes it easy to
     generate generic trees. While it is easy to write a grammar and a
     lexical analyzer using modules like \texttt{Parse::Yapp} and
     \texttt{Parse::Lex}, this pair of tools is not as efficient as I
     would like. In this document I'll present a way to cook quickly
     \texttt{Parse::Yapp} with the better lexical analyzer I know:
     \texttt{flex}.
  }
}
@InProceedings{APL2k2.Parguess,
  author = "J.J. Almeida and Alberto Manuel Simões and José Alves Castro",
  title     = "Extracção de corpora paralelo a partir da web: construção e
disponibilização",
  booktitle={Actas do XVIII Encontro da Associação Portuguesa de Linguística},
 address={Porto 2002},
  year      = "2003",
  lang      = "PT",
  url       = {http://alfarrabio.di.uminho.pt/~albie/publications/APL2k2.Parguess.pdf},
  abstract  = {
   Ao longo deste documento descrever-se-á um conjunto de ferramentas
   construídas para extracção automática de recursos bilingues a partir
   da Web, a partir de um \emph{site} específico, a partir de um
   sistema de ficheiros contendo alguns textos que sejam traduções de outros,
   ou ainda a partir de memórias de tradução.

   Neste trabalho apresenta-se todo o processo de construção de corpora
   paralelo desde os algoritmos de minagem dos dados (data mining) até à
   construção de vários tipos de recursos bilingues incluindo a construção
   automática de corpus paralelos pesquisáveis na Internet.
  }
}

@InProceedings{APL2k2.Synthesis,
  author = "J.J. Almeida and Alberto Manuel Simões",
  title     = "Geração de voz com sotaque",
  booktitle={Actas do XVIII Encontro da Associação Portuguesa de Linguística},
  address={Porto 2002},
  year      = "2003",
  url       = {http://alfarrabio.di.uminho.pt/~albie/publications/APL2k2.Synthesis.pdf},
  lang      = "PT",
  abstract  = {
   Como é sabido os sotaques podem estar ligados a uma zona geográfica,
   a um grupo social, podem até ser uma característica pessoal.  O seu
   estudo e descrição tem interessado muitos investigadores embora
   normalmente esse estudo tem sido feito de modo pouco formal.

   No trabalho que aqui se relata, tentou-se descrever formalmente
   sotaques e disfunções através de criação de regras a integrar como
   variantes num gerador de voz.  Deste modo, pretendeu-se criar um
   ambiente de experimentação dos modelos construídos para descrever
   algumas características de certos sotaques ou certas disfunções, de
   modo a permitir a sua validação.

   Constatou-se que se consegue obter certas disfunções e certos
   sotaques com facilidade por simples acrescento de regras opcionais
   em certas fases da geração da voz. Outros, aparentam ser de maior
   dificuldade, ou por não conhecermos suficiente bem os fenómenos
   neles envolvidos ou envolverem maior complexidade prosódica.
  },
}

@InProceedings{xata:xmldt,
  author    = "J.J. Almeida and Alberto Manuel Simões",
  title     = "Engenharia reversa de {HTML} usando tecnologia {XML}",
  booktitle = "{XATA --- XML}, Aplicações e Tecnologias Associadas",
  year      = "2003",
  url =
{http://alfarrabio.di.uminho.pt/~albie/publications/xata2003xml.pdf},
  lang      = "PT",
  abstract  = { O proliferar de ferramentas criadores de HTML e o uso
                  de HTML guiado pelo aspecto, tem vindo a arruinar o
                  seu lado conceptual. Este problema foi reconhecido e
                  deu origem a vários formatos ou tecnologias com o
                  objectivo de separar o aspecto do conceito.  No
                  entanto a realidade actual mostra uma enorme
                  quantidade de páginas HTML com péssima leitura
                  conceptual e estrutural, invalidando uma série de
                  usos possíveis da informação nelas contida.  Nesta
                  comunicação apresenta-se um trabalho (em fase
                  inicial) que pretende fazer engenharia reversa de
                  HTML para permitir aumentar a sua acessibilidade, a
                  fim de ser usada num \emph{browser} para invisuais.
                  },
  editor ="José Carlos Ramalho",
}

@InProceedings{xata:museudapessoa,
  author = "Alberto Manuel Simões and J.J. Almeida",
  title     = {{H}istórias de {V}ida + {P}rocessamento {E}strutural = {M}useu
da {P}essoa},
  booktitle = "{XATA --- XML}, Aplicações e Tecnologias Associadas",
  year      = "2003",
  lang      = "PT",
  abstract  = {
   Este artigo apresenta a arquitectura actual do Museu da Pessoa,
   contemplando a forma como os documentos estão a ser editador,
   catalogados, arquivados, e processados para a criação das estruturas
   necessárias ao Museu.
},
url = {http://alfarrabio.di.uminho.pt/~albie/publications/xata2003mp.pdf},
  editor ="José Carlos Ramalho",
}

@InProceedings{elpub2003,
  author = "Alberto Manuel Simões and J.J. Almeida",
  year= 2003,
  title= "Music publishing",
  isbn = "972-98921-2-1",
  note = {Guimarães},
  publisher = "Universidade do Minho",
  url = {http://alfarrabio.di.uminho.pt/~albie/publications/elpub2003.pdf},
  editor ="Sely Costa et al.",
  booktitle= "ElPub 2003 -- International conference on electronic publishing",
  month = "June",
  pages = "288--298",
  lang="EN",
  abstract = {
     Current music publishing in the Internet is mainly concerned with
  sound publishing. We claim that music publishing is not only to make
  sound available but also to define relations between a set of music
  objects like music scores, guitar chords, lyrics and their
  meta-data. We want an easy way to publish music in the Internet, to
  make high quality paper booklets and even to create Audio CD's.
  In this document we present a workbench for music publishing based
  on open formats, using open-source tools and script programming over
  them.  The workbench is based on an archive specification written in
  a text-based format which includes sound references, music scores,
  chords and lyrics and their meta-information.
  },

 keyword ="música, bibliotecas digitais",
}

@InProceedings{cp3a:terminum2003,
  author = "J.J. Almeida and Alberto Simões and José Castro and Bruno
     Martins and Paulo Silva",
  year= 2003,
  title= "Projecto {TerminUM}",
  publisher = "Universidade do Minho",
  booktitle={CP3A 2003 -- Workshop em Corpora Paralelos: aplicações e
    algoritmos associados},
  note = {Braga},
  month="Jun.",
  pages = "7--14",
 keyword ="terminum, parallel corpora",
   url = {http://alfarrabio.di.uminho.pt/~albie/publications/cp3a2003-terminum.pdf},
  abstract = { O projecto TerminUM tem como objectivos principais o
                  estudo, experimentação e a criação de recursos na
                  área dos corpora paralelos, terminologia
                  (descritiva) e recursos multilingues ligados a
                  corpora: fazer extracção tão automática quanto
                  possível de corpora a partir da web; fazer extracção
                  de dicionários, de terminologia e de outros recursos
                  ligados à tradução; criar e interligar as
                  ferramentas desenvolvidas; criar e disponibilizar:
                  (1) listas de Bitextos, corpora e corpora paralelos,
                  (2) ferramentas de criação e transformação de
                  corpora, (3) recursos multilingues derivados/ligados
                  a corpora.  Nesta apresentação serão abordadas
                  algumas tarefas presentemente a decorrer no âmbito
                  do projecto, nomeadamente: ciclo de vida da
                  construção e transformação de corpora; resumo das
                  ferramentas desenvolvidas (e em desenvolvimento);
                  construção de corpora paralelos tomando como base
                  legendas de filmes (subtitles), ficheiro de
                  internacionalização (mensagens de software .po) e
                  ficheiros de memórias de tradução (TMX); animação de
                  corpora paralelos via web (criação de motores de
                  consulta usando diversas ferramentas).  }
}

@InProceedings{cp3a:kvec2003,
  author = "Bruno Martins",
  year= 2003,
  title= "{Lingua-Biterm}: um módulo Perl para extracção de terminologia bilingue",
  publisher = "Universidade do Minho",
  booktitle={CP3A 2003 -- Workshop em Corpora Paralelos: aplicações e
    algoritmos associados},
  note = {Braga},
  month="Jun.",
  pages = "65--70",
 keyword ="kvec, terminum, parallel corpora, word alignment",
}

@InProceedings{cp3a:natools2003,
  author = "Alberto Simões",
  year= 2003,
  title= "Alinhamento de corpora paralelos",
  publisher = "Universidade do Minho",
  booktitle={CP3A 2003 -- Workshop em Corpora Paralelos: aplicações e
    algoritmos associados},
  note = {Braga},
  month="Jun.",
  pages = "71--77",
 keyword ="natools, terminum, parallel corpora, word alignment",
}

@article{sepln2003,
 author= {Alberto M. Simões and J.J. Almeida},
 title="{NATools} -- A Statistical Word Aligner Workbench",
 publisher="Sociedade Española para el Procesamiento del Lenguaje Natural",
  journal =    {Procesamiento del Lenguaje Natural},
 volume ="31",
 pages = "217--224",
 month="Sep.",
 year= 2003,
 abstract = {This document presents the TerminUM project and the
  work done in its statistical word aligner workbench (NATools). It
  shows a variety of alignment methods for parallel corpora and
  discusses the resulting terminological dictionaries and their use:
  evaluation of sentence translations; construction of a multi-level
  navigation system for linguistic studies or statistical
  translations. },
 keyword ="natools, terminum, parallel corpora, word alignment",
}

@phdthesis{tesejj,
  author =       {José João Dias de Almeida},
  title =        {Dicionários dinâmicos multi-fonte},
  school =       {Universidade do Minho},
  type =         "Tese de Doutoramento",
  superviser =   "Pedro Rangel Henriques",
  url=           "http://natura.di.uminho.pt/~jj/bib/tesejj.pdf",
  year =         2003,
  lang      = "PT",
}

@MastersThesis{teseambs,
  author =       {Alberto Manuel Brandão Simões},
  title =        {Parallel Corpora word alignment and applications},
  school =       {Escola de Engenharia - Universidade do Minho},
  url=           "http://alfarrabio.di.uminho.pt/~albie/publications/msc.pdf",
  type =         "Tese de Mestrado",
  superviser =   "José João Almeida and Pedro Rangel Henriques",
  year =         {2004},
  lang      = "EN",
}

@InProceedings{xata04:tx,
  author =       {José João Almeida and Alberto Simões},
  title =        {{TX} --- {V}alidação de {XML} baseada em tipos dinâmicos},
  booktitle =    {{XATA 2004} - XML, Aplicações e Tecnologias Associadas},
  pages =        {217--224},
  year =         {2004},
  url =
{http://alfarrabio.di.uminho.pt/~albie/publications/xata04-tx.pdf},
  lang      = "PT",
  isbn =         {972-99166-0-8},
  editor =       {José Carlos Ramalho and Alberto Simões},
  month =        {February},
  abstract = {
  Desde o advento do SGML e posteriormente do XML, que a validação de
  documentos tem sido focada.
  
  Esta validação surgiu para analisar a estrutura dos documentos SGML
  e XML usando DTDs.  Além dessa, e devido às restrições do XML em
  relação ao SGML, a validação de XML bem formado também tem sido
  usada.  Mais recentemente, os Schema e Schematron vieram permitir a
  validação a um nível superior: não só a estrutura do documento mas
  também alguma validação de conteúdo.
  
  Neste artigo apresentamos a ferramenta TX que visa outro nível de
  validação, em que os tipos possam ser mais ricos e/ou calculados
  dinamicamente, e onde se possa definir funções de anotação e/ou
  correcção das porções do documento que não sigam as especificações.
  }
}



@InProceedings{xata04:mtd,
  author =       {Alberto Simões and José João Almeida and Xavier Gomez
Guinovart},
  title =        {Memórias de Tradução Distribuídas},
  booktitle =    {{XATA 2004} --- XML, Aplicações e Tecnologias Associadas},
  pages =        {59--68},
  year =         {2004},
  lang      = "PT",
  url = {http://alfarrabio.di.uminho.pt/~albie/publications/xata04-mtd.pdf},
  isbn =         {972-99166-0-8},
  editor =       {José Carlos Ramalho and Alberto Simões},
  month =        {February},
  abstract = {
  Neste documento apresenta-se o conceito de memórias de tradução
  distribuídas, discutindo-se o seu interesse na área da tradução, bem
  como as vantagens que uma ferramenta de tradução pode tirar do seu
  uso.
  
  É apresentada uma possível implementação de memórias de tradução
  distribuídas usando WebServices numa arquitectura de cooperativismo.
  São definidos as mensagens (API) que um serviço deste género deve
  implementar para que uma ferramenta de tradução possa tirar partido
  da colaboração entre tradutores.
  }
}

@article{xmldt2,
  author = {Alberto Simões},
  title = {{XML::DT} - Down-Translating XML},
  journal = {The Perl Review},
  number = 1,
  volume = 1,
  year = 2004,
}

@article{sepln2004,
 author= {Alberto Simões and Xavier Gómez Guinovart and J.J. Almeida},
 title={Distributed Translation Memories implementation using WebServices},
 publisher="Sociedade Española para el Procesamiento del Lenguaje Natural",
 journal =      {Procesamiento del Lenguaje Natural},
  pages =        {89--94},
  volume =       {33},
  month =        {July},
  year =         {2004},
  lang =         {EN},
 url = {http://alfarrabio.di.uminho.pt/~albie/publications/dtm-sepln.pdf},
 keyword ={TMs, MT, distributed translation memories, WebServices, CAT},
 abstract= { Translation Memories are very useful for translators
  but are difficult to share and reuse in a community of translators.
  This article presents the concept of Distributed Translation
  Memories, where all users can contribute and sharing translations.
  Implementation details using WebServices are shown, as well as an
  example of a distributed system between Portugal and Spain.}
}

@inproceedings{linguateca,
 author = {Diana Santos and Alberto Simões and Ana Frankenberg-Garcia and 
   Ana Pinto and Anabela Barreiro and Belinda Maia and Cristina Mota and Débora
   Oliveira and Eckhard Bick and Elisabete Ranchhod and J.J. Almeida
   and Luís Cabral and Luís Costa and Luís Sarmento and Marcirio Chaves and Nuno
   Cardoso and Paulo Rocha and Rachel Aires and Rosário Silva and Rui Vilela and Susana Afonso},
 title = {Linguateca: um centro de recursos distribuído para o processamento
   computacional da língua portuguesa},
 year = 2004,
 booktitle = {Workshop on Linguistic Tools and Resources for Spanish and
   Portuguese},
 editor = {IBERAMIA 2004},
 lang = "EN",
 pages="147--154",
 address="Puebla, México",
 url = {http://alfarrabio.di.uminho.pt/~albie/publications/linguateca.pdf},
 abstract = {
   Neste artigo apresentamos uma panorâmica da actividade da Linguateca na criação
   e disponibilização de recursos e ferramentas para a língua portuguesa.  Começamos
   por uma descrição dos objectivos e pressupostos da Linguateca e uma breve história
   da sua intervenção, e finalizamos com algumas considerações sobre a melhor forma
   de prosseguir na organização da área.
 }
}


@inproceedings{xata05:fs,
    author="Rui Vilela and Alberto Simões and Eckhard Bick and J.J. Almeida",
    title="Representação em {XML} da {F}loresta {S}intáctica",
    month="Fev.",
    year=2005,
    editor="José Carlos Ramalho and Alberto Simões and João Correia Lopes",
    booktitle="XATA 2005, Aplicações e Tecnologias Associadas",
    publisher="Departamento de Informática, Universidade do Minho",
    location="Braga",
    keyword = {XML, Floresta Sintáctica, tigerXML, Lingua::PT::Dirty},
}

@inproceedings{xata05:tdt,
    author="J.J. Almeida and Alberto Simões",
    title="Inferência de tipos em documentos {XML}",
    month="Fev.",
    year=2005,
    editor="José Carlos Ramalho and Alberto Simões and João Correia Lopes",
    booktitle="XATA 2005, Aplicações e Tecnologias Associadas",
    publisher="Departamento de Informática, Universidade do Minho",
    location="Braga",
    keyword = {XML, XML::DT},
}

@inproceedings{xata06:navegante,
    author="J.J. Almeida and Alberto Simões",
    title="Navegante: um proxy de ordem superior para navegação intusiva",
    month="Fev.",
    year=2006,
    editor="José Carlos Ramalho and Alberto Simões and João Correia Lopes",
    booktitle="XATA 2006, Aplicações e Tecnologias Associadas",
    publisher="ESTGP",
    address =      {Portalegre},
    Note="poster",
    pages="376--377",
    keyword = {XML, XML::DT, HTML},
}

@inproceedings{xata06:xmlauto,
    author="J.J. Almeida and Alberto Simões",
    title =        {Geração dinâmica de {API}s {P}erl para criação de {XML}},
    month="Fev.",
    year=2006,
    editor="José Carlos Ramalho and Alberto Simões and João Correia Lopes",
  booktitle =    {{XATA 2006} --- 4ª Conferência Nacional em XML, Aplicações e Tecnologias Aplicadas},
    publisher="ESTGP",
  url = {http://alfarrabio.di.uminho.pt/~albie/publications/xata2006-xmlwritersimple.pdf},
  address =      {Portalegre},
    pages="307--314",
    keyword = {XML, XML::DT, HTML},
  isbn =         {972-99166-2-4},
  lang =         "PT",
  abstract =     {
  É consensual que o XML como linguagem para a estruturação de documentos
  tem vindo a tomar um lugar relevante. É também evidente a vantagem
  obtida no uso de XML como linguagem de intercâmbio.
  No entanto, a sua sintaxe é
  demasiado descritiva pelo que a geração de documentos de forma
  manual é dolorosa sendo útil dispor de módulos
  que simplifiquem essa tarefa.

  Neste artigo propomos um módulo Perl (XML::Writer::Simple) configurável via
  DTD que simplifica a tarefa de gerar XML.
  },
}

@article{sepln06,
  author =       {Alberto Simões and J. João Almeida},
  title =        {{NatServer:} A Client-Server Architecture for building Parallel Corpora applications},
  year =         {2006},
  journal =    {Procesamiento del Lenguaje Natural},
  address =      {Zaragoza, Spain},
  url = {http://alfarrabio.di.uminho.pt/~albie/publications/sepln06.pdf},
  month =        {September},
  lang =         {EN},
  volume =       {37},
  pages =        {91--97},
  abstract =     {Parallel corpora are important resources for most
                  Natural Language processing tasks. From the common
                  applications, like machine translation, to the
                  usually mono-lingual tasks as paraphrase detection
                  and word sense disambiguation, most researchers are
                  using massive parallel corpora.  Thus, the
                  availability of an efficient way to manage them is
                  very important.  This paper presents a Client-Server
                  architecture to query efficiently parallel corpora
                  and probabilistic translation dictionaries.},
}

@inProceedings{eamt06,
  author =       {Alberto Simões and J. João Almeida},
  title =        {Combinatory Examples Extraction for Machine Translation},
  shortin = {{EAMT}},
  year =         {2006},
  url = {http://alfarrabio.di.uminho.pt/~albie/publications/eamt06.pdf},
  booktitle = {11th Annual Conference of the European Association for Machine Translation},
  editor =     {Jan Tore L\o nning and Stephan Oepen},
  address =   {Oslo, Norway},
  pages =     {27--32},
  month =     {19--20, June},
  isbn =      {82-7368-294-3},
  lang = {EN},
  abstract = { One of the bottlenecks of example-based machine
                  translation (EBMT) is to be able to amass
                  automatically quantities of good examples.  In our
                  work in EBMT, we are investigating how far one can
                  go by performing example extraction from parallel
                  corpora using Probabilistic Translation Dictionaries
                  to obtain example segmentation points.  In fact, the
                  success of EBMT highly depends on examples quality
                  and quantity, but also in their length. Thus, we
                  give special importance on methods to extract
                  different size examples from the same translation
                  unit.  With this article we show that it is possible
                  to extract quantities for examples from parallel
                  corpora just using probabilistic translation
                  dictionaries extracted from the same corpora.},
}


@InProceedings{lrec06,
  author =       {José João Almeida and Alberto Simões},
  title =        {{$T_2O$} --- Recycling Thesauri into a Multilingual Ontology},
  shortin = {{LREC}},
  booktitle =    {Fifth international conference on Language Resources and Evaluation, LREC 2006},
  year =         {2006},
  url = {http://alfarrabio.di.uminho.pt/~albie/publications/lrec06.pdf},
  address =      {Genova, Italy},
  month =        {May},
  lang =         {EN},
  abstract =     {In this article we present $T_2O$ --- a workbench to
                  assist the process of translating heterogeneous
                  resources into ontologies, to enrich and add
                  multilingual information, to help programming with
                  them, and to support ontology publishing. $T_2O$ is
                  an ontology algebra.},
}

@inProceedings{elpub06-t2o,
  author =       {J. João Almeida and  Alberto Simões },
  title =        {Publishing multilingual ontologies: a quick way of obtaining feedback},
  year =         {2006},
  booktitle =    {{ElPub 2006} --- Digital Spectrum: Integrating Technology and Culture},
  address =   {Bansko, Bulgaria},
  pages = "373--374",
  note="poster",
  url = {http://alfarrabio.di.uminho.pt/~albie/publications/elpub06-t2o.pdf},
  month =     {June},
  lang = {EN},
  abstract = {Dictionary and Thesaurus are valuable resources for
                  Natural Language Processing but do not exist as
                  freely available as expected, especially for
                  languages other than English and, when they exist,
                  they are just available for querying online. Our
                  main goal with T2O --- Thesaurus to Ontology
                  framework --- is to create a multilingual ontology:
                  freely available online and to download; with a
                  computer readable format; with a good API; with a
                  structure as rich as possible; reusing all the
                  structured information we can get; },
}



@InProceedings{elpub06-blind,
  author =       {António R. Fernandes and Alexandre Carvalho and J. João Almeida and  Alberto Simões },
  title =        {Transcoding for Web Accessibility for the Blind: Semantics
from Structure},
  shortin = {{ElPub}},
  booktitle = {ElPub 2006 --- Digital Spectrum: Integrating Technology and Culture},
  year =      {2006},
  url  = {http://alfarrabio.di.uminho.pt/~albie/publications/elpub06-blind.pdf},
  address =   {Bansko, Bulgaria},
  month =     {June},
  pages = {123-134},
  abstract = {True accessibility requires minimizing the scanning time
                  to find a particular piece of
                  information. Sequentially reading web pages do not
                  provide this type of accessibility, for instance
                  before the user gets to the actual text content of
                  the page it has to go through a lot of menus and
                  headers. However if the user could navigate a web
                  page based through semantically classified blocks
                  then the user could jump faster to the actual
                  content of the page, skipping all the menus and
                  other parts of the page. We propose a transcoding
                  engine that tackles accessibility at two distinct,
                  yet complementary, levels: for specific known sites
                  and general unknown sites. We present a tool for
                  building customized scripts for known sites that
                  turns this process in an extremely simple task,
                  which can be performed by anyone, without any
                  expertise. For general unknown sites, our approach
                  relies on statistical analysis of the structural
                  blocks that define a web page to infer a semantic
                  for the block.},
   lang = "EN",
}

% ^^^^^ 2007 ^^^^^^^^^^

%InProceedings{gfkl07:topology,
%  author =       {Anália Lourenço and Alberto Simões and Orlando Belo},
%  title =        {Evaluating Web Site Structure based on Navigation Profiles and Site Topology},
%  booktitle =    {The 31st Annual Conference of the German Classification Society on Data Analysis, Machine Learning, and Applications},
%  year =         {2007},
%  note =         {\textbf{forthcoming}},
% }


%InProceedings{gfkl07:terminology,
%  author =       {Alberto Simões and José João Almeida},
%  title =        {Using Alignment Patterns for Bilingual Terminology Extraction},
%  booktitle =    {The 31st Annual Conference of the German Classification Society on Data Analysis, Machine Learning, and Applications},
%  year =         {2007},
%  note =         {\textbf{forthcoming}},
% }


%InProceedings{gfkl07:music,
%  author =       {Alberto Simões and Anália Lourenço and José João Almeida},
%  title =        {Mining Classical Music Scores for Epoch Classification},
%  booktitle =    {The 31st Annual Conference of the German Classification Society on Data Analysis, Machine Learning, and Applications},
%  year =         {2007},
%  note =         {\textbf{forthcoming}},
% }


@InCollection{avalon:jspell,
  author =       {José João Almeida and Alberto Simões},
  title =        {Jspellando nas morfolimpíadas: Sobre a participação do {Jspell} nas Morfolimpíadas},
  booktitle =    {Avaliação conjunta: um novo paradigma no processamento computacional da língua portuguesa},
  shortin =      {Avaliação conjunta, cap. 8},
  year =         {2007},
  editor =       {Diana Santos},
  pages =        {83--90},
  publisher =    {{IST Press}},
}

@InCollection{avalon:avalinha,
  author =       {Alberto Simões and José João Almeida},
  title =        {Avaliação de alinhadores},
  shortin =      {Avaliação conjunta, cap. 18},
  booktitle =    {Avaliação conjunta: um novo paradigma no processamento computacional da língua portuguesa},
  publisher =    {{IST Press}},
  year =         {2007},
  pages =        {219--230},
  editor =       {Diana Santos},
}

@InProceedings{xata07:xmltmx,
  author =       {José João Almeida and Alberto Simões},
  title =        {{XML::TMX} --- Processamento de Memórias de Tradução de Grandes Dimensões},
  shortin = {{XATA}},
  booktitle =    {{XATA 2007} --- 5ª Conferência Nacional em XML, Aplicações e Tecnologias Aplicadas},
  year =         {2007},
  month =        {February},
  url = {http://alfarrabio.di.uminho.pt/~albie/publications/xmltmx07.pdf},
  pages =        {83--93},
  isbn =         {978-972-99166-4-9},
  editor =       {José Carlos Ramalho and João Correia Lopes and Luís Carríço},
  abstract =     { As ferramentas de tradução assistida por computador
                  tentam reutilizar as traduções realizadas pelo
                  tradutor sempre que uma frase semelhante tenha sido
                  já traduzida. Para o intercâmbio destes documentos
                  foi definido um formato denominado TMX (Translation
                  Memory Exchange) baseado em XML.  Este tipo de
                  documento ganha facilmente tamanhos incomportáveis
                  para o seu processamento com métodos tradicionais.
                  Neste artigo propomos uma metodologia de ordem
                  superior para o processamento de documentos de
                  estrutura repetitiva (em que se inserem as memórias
                  de tradução) com uma abordagem baseada na conjunção
                  de SAX e DOM.  São apresentados vários exemplos de
                  filtros sobre memórias de tradução bem como um
                  conjunto de medidas da sua eficiência.  }
}

% InProceedings{xata07:xmlyamljson,
%    author =       {Rúben Fonseca and Alberto Simões},
%   title =        {Alternativas ao {XML}: {YAML} e {JSON}},
%   booktitle =    {{XATA 2007} --- 5ª Conferência Nacional em XML, Aplicações e Tecnologias Aplicadas},
%   year =         {2007},
%   month =        {February},
%   url = {http://alfarrabio.di.uminho.pt/~albie/publications/xmlyamljson07.pdf},
%   pages =        {33--46},
%   isbn =         {978-972-99166-4-9},
%   editor =       {José Carlos Ramalho and João Correia Lopes and Luís Carríço},
%   abstract =     { O XML tem sido eleito como a linguagem de anotação por excelência,
% possuindo ao mesmo tempo boas capacidades para serialização de estruturas
% computacionais e transporte de dados independente da plataforma.
% Recentemente porém, novos formatos de dados têm surgido. Alguns deles
% têm tido uma boa aceitação porque resolvem alguns problemas ou limitações
% do XML, sendo em algumas situações um bom complemento ou substituto do mesmo.
% Neste artigo iremos apresentar dois desses formatos de dados - o YAML e o
% JSON - fazendo uma abordagem geral dos mesmos e analisando algumas métricas
% que nos poderão ajudar a decidir se e quando usar estas alternativas.
%  }
% }

% techreport{man:rena,
%   author = "Edgar Alves and José João Almeida",
%   title = "Manual de Utilizador do {RENA}",
%   year = 2006,
%   type = "Manual",
%   month = "Jul",
%   institution = umdi,
%   keyword = "REM, PLN, IR",
%   abstract = {},
%   url = "http://natura.di.uminho.pt/~jj/pln/rena.pdf",
% }

@InProceedings{MP07,
  author =       {Alberto Simões and Rúben Fonseca and José João Almeida},
  title =        {{Makefile::Parallel} Dependency Specification Language},
  booktitle =    {Euro-Par 2007},
  year =         {2007},
  address =      {Rennes, France},
  month =        {August},
  pages =	 {33--41},
  editor =	 {Anne-Marie Kermarrec and Luc Bougé and Thierry Priol},
  volume =	 {4641},
  series =	 {LNCS},
  publisher =	 {Springer-Verlag},
  abstract =     {  Some processes are not easy to be programmed from scratch
for
  parallel machines (clusters), but can be easily split on simple
  steps. Makefile::Parallel is a tool which lets users to specify how processes
  depend on each other.

  The language syntax resembles the well known Makefile
  makefiles format, but instead of specifying files or targets
  dependencies, Makefile::Parallel specifies processes (or jobs) dependencies.

  The scheduler submits jobs to the cluster scheduler (in our case,
  Rocks PBS) waiting them to end. When each process finishes,
  dependencies are calculated and direct dependent jobs are submitted.

  Makefile::Parallel language includes features to specify parametric rules,
used
  to split and join processes dependencies.  Some tasks can be split
  into n smaller jobs working on different portions of files. At the
  end, another process can be used to join the results.
},
}


@InProceedings{epia-bio-2007,
  booktitle = {New Trends in Artificial Intelligence},
  editor = {José Neves and Manuel Filipe Santos and José Manuel Machado},
  pages = {541--552},
  isbn13 = {978-989-95618-0-9},
  author =       { Anália  Lourenço and Alberto  Simões and José João Almeida  and
Miguel  Rocha and  Isabel  Rocha and Eugénio  Ferreira},
  title =        {An Ontology-Based Approach To Systems Biology Literature
Retrieval and Processing},
  shortin = {Epia, CMBSB},
  year =         {2007},
  month =        {December},
  abstract =     {This paper details the \emph{SysBio Explorer}, a
                  Systems Biology Literature Retrieval and Processing
                  Framework, whose aim relies on the automatic
                  inference of regulatory and metabolic networks based
                  on biomedical literature. The \emph{SysBio Explorer}
                  does not focus on any organism or problem in
                  particular and encompasses a number of processing
                  and analysis techniques. It works over full-text
                  documents, applying Natural Language Processing
                  techniques and using biomedical dictionaries and
                  ontologies together with hand-made rules. Besides
                  biological entity recognition and relation
                  extraction, document classification, relevance
                  assessment and authoring networks are also within
                  its present scope. The framework is described in
                  terms of its design requirements and implementation
                  decisions, exposing current achievements, but also
                  highlighting present obstacles and future
                  work. Experiments over real-world problems
                  concerning the organisms \emph{E. coli},
                  \emph{S. cerevisiae} and \emph{H. pylori} are used
                  in its validation.}
}

@InProceedings{epia-music-2007,
  booktitle = {New Trends in Artificial Intelligence},
  editor = {José Neves and Manuel Filipe Santos and José Manuel Machado},
  shortin = {Epia, TEMA},
  pages = {791--799},
  author =       {Alberto Simões and Anália Lourenço and José João Almeida},
  title =        {Using Text Mining Techniques for Classical Music Scores
Analysis},
  year =         {2007},
  month =        {December},
  abstract =     {Music Classification is a particular area
                  of Computational Musicology that provides valuable
                  insights about the evolving of composition patterns
                  and assists in catalogue generation. The proposed work
                  detaches from former works by classifying music based
                  on music score information. Text Mining techniques
                  support music score processing while Classification
                  techniques are used in the construction of decision
                  models. Although research is still at its earliest
                  beginnings, the work already provides valuable
                  contributes to symbolic music representation processing 
                  and subsequent analysis. Score processing involved
                  the counting of ascending and descending chromatic
                  intervals, note duration and meta-information
                  tagging. Analysis involved feature selection and
                  the evaluation of several data mining algorithms,
                  ensuring extensibility towards larger repositories or
                  more complex problems. Experiments report the analysis
                  of composition epochs on a subset of the Mutopia project 
                  open archive of classical LilyPond-annotated
                  music scores.  
  },
}


@InCollection{harem:rena,
  author =       {J.João Almeida},
  title =        {{RENA} - Reconhecedor de Entidades},
  booktitle =    {Reconhecimento de entidades mencionadas em português},
  year =         {2007},
  note = {Documentação e actas do HAREM, a primeira avaliação conjunta na
área},
  pages =        {157-172},
  url = {http://acdc.linguateca.pt/aval_conjunta/LivroHAREM/Cap13-SantosCardoso2007-Almeida.pdf},
  ISBN = {978-989-20-0731-1},
  editor =       {Diana Santos and Nuno Cardoso},
  publisher = {Linguateca},
  shortin ={{HAREM} cap. XIII},
}

@Article{sepln07,
  author =       {Alberto Simões and José João Almeida},
  title =        {Parallel Corpora based Translation Resources Extraction},
  journal =      {Procesamiento del Lenguaje Natural},
  year =         {2007},
  pages =        {265--272},
  volume =       {39},
  month =        {September},
  lang =         {EN},
  abstract =     {This paper describes NATools, a toolkit to process,
                  analyze and extract translation resources from
                  Parallel Corpora. It includes tools like a
                  sentence-aligner, a probabilistic translation
                  dictionaries extractor, word-aligner, a corpus
                  server, a set of tools to query corpora and
                  dictionaries, as well as a set of tools to extract
                  bilingual resources.}
}

@InProceedings{cgiauto08,
  author =       {Davide Sousa and Alberto Simões and José João Almeida},
  title =        {{CGI::Auto} --- Automatic Web-Service Creation},
  booktitle =    {{XATA 2008} --- 6ª Conferência Nacional em XML, Aplicações e
Tecnologias Aplicadas},
  year =         {2008},
  month =        {February},
  url = {http://alfarrabio.di.uminho.pt/~albie/publications/cgiauto08.pdf},
  pages =        {22--27},
  isbn =         {978-972-99166-5-6},
  editor =       {José Carlos Ramalho and João Correia Lopes and Salvador
Abreu},
  abstract =     {   The creation of a CGI or a WebService as an interface for
a command line tool is
not as unusual as it may seem. It is extremely usual and useful.

There are applications developed as command line tools that can be useful for
different purposes,
and different kind of users. Some of these users might not be able to run
these tools directly.
For instance, it
is not easy to install a bunch of Perl modules to have a small tool working.
For these situations, it is easier to make the tool available in the Web or as
a
WebService.

The problem with making the tool available in these fashions, is that
programmers tend to rewrite
the tools to incorporate the CGI or XML specific layers.

We defend that these CGI or WebService interfaces should use the already
available command line
 tool, without any change. This interface should be able to read a simple
textual
specification of how the command line tool works, and buid the CGI or XML
specific layers
automatically.

The CGI::Auto module aims this purpose:
to encapsulate command line tools in a CGI layer based on a textual
specification, transforming
the command line tool in a web application.

 }
}


@InProceedings{navegante08,
  author =       {Nuno Carvalho and José João Almeida and Alberto Simões},
  title =        {{NAVEGANTE} --- An Intrusive Browseing Framework},
  booktitle =    {{XATA 2008} --- 6ª Conferência Nacional em XML, Aplicações e
Tecnologias Aplicadas},
  year =         {2008},
  month =        {February},
  url = {http://alfarrabio.di.uminho.pt/~albie/publications/navegante08.pdf},
  pages =        {52--63},
  isbn =         {978-972-99166-5-6},
  editor =       {José Carlos Ramalho and João Correia Lopes and Salvador
Abreu},
  abstract =     {   NAVEGANTE is a generic framework to build superior order
proxies for
  intrusive browsing. This framework provides the means for developing
  tools that behave as proxies, but perform some processing task on
  the content that is being browsed. Parallel to this content processing,
  applications can also run other user-defined functions with different
  purposes and interfaces, but we'll explain those later. Currently,
  NAVEGANTE only builds applications that run as CGIs, but this is intended
  to change in a near future. Applications are built writing programs in
  NAVEGANTE's Domain Specific Language (DSL).

  NAVEGANTE is a work in progress. This article aims to describe the current
  state of development. What applications can be built and how. Also, we
  identify some implementation problems, and briefly discuss some future
  improvements. Finally, we try to illustrate most of the concepts described
  using a couple of case studies.
 }
}

@Article{sepln08,
  author =       {Alberto Simões and José João Almeida},
  title =        {Bilingual Terminology Extraction based on Translation
Patterns},
  journal =      {Procesamiento del Lenguaje Natural},
  year =         {2008},
  month =        {September},
  lang =         {EN},
  abstract =     {Parallel corpora are rich sources of translation
    resources. This document presents a methodology for the extraction
of bilingual
    nominals (terminology candidates) from parallel corpora, using
translation patterns.
    The patterns proposed in this work specify the order changes that
occur during translation
    and that are intrinsic to the involved languages syntaxes.
    These patterns are described in a domain specific language
    named PDL (Pattern Description Language), and are extremely
    efficient for the detection of nominal phrases.
  },
  volume = {41},
  pages = {281--288},
}


@inproceedings{propor-apslt08,
  author    = { J. J. Almeida and  Alberto Simões},
  title     = { A Textual Rewriting system for NLP},
  booktitle = {Applications of Portuguese Speech and Language Technologies, 
               PROPOR 2008 Special session},
  year      = {2008},
  pages     = {35--42},
  editor    = {António Teixeira and Daniela Braga},
}

@inproceedings{epia:DruryA09,
  author    = {Brett Drury and J. J. Almeida},
  title     = {Construction of a Local Domain Ontology from News Stories},
  booktitle = {EPIA},
  year      = {2009},
  pages     = {400-410},
  url       = {http://dx.doi.org/10.1007/978-3-642-04686-5_33},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {5816},
  note     = {Progress in Artificial Intelligence, EPIA 2009, Aveiro, Portugal, October 12-15},
  editor    = {Luis Seabra Lopes and
               Nuno Lau and
               Pedro Mariano and
               Luis Mateus Rocha},
}

@InProceedings{markers09,
  author =       {Alberto Simões and José João Almeida},
  title =        {Bilingual Example Segmentation based on Markers
Hypothesis},
  booktitle =   {I Iberian SLTech 2009},
  editor  = { António Teixeira and Miguel Sales Dias and Daniela Braga},
  year =         {2009},
  address = {Porto Salvo, Portugal},
  month = {September, 3--4},
  isbn = {978-989-96278-1-9},
  pages = {95--98},
  lang = {EN},
  abstract = {  The Marker Hypothesis was first defined by Thomas Green
in 1979.  It
  is a psycho-linguistic hypothesis defining that there is a set of
  words in every language that marks boundaries of phrases in a
  sentence. While it remains a hypothesis because nobody has proved
  it, tests have shows that results are comparable to basic shallow
  parsers with higher efficiency.

  The chunking algorithm based on the Marker Hypothesis is simple,
  fast and almost language independent. It depends on a list of
  closed-class words, that are already available for most languages.
  This makes it suitable for bilingual chunking (there is not the
  requirement for separate language shallow parsers).

  This paper discusses the use of the Marker Hypothesis combined
  with Probabilistic Translation Dictionaries for example-based machine
  translation resources extraction from parallel corpora.},
}

@article{ocr2010,
 author = {Brett Drury and José João Almeida},
title = {A Case Study of Rule Based and Probabilistic Word Error Correction of Portuguese OCR Text in a "Real World" Environment for Inclusion in a Digital Library},
   journal={International Journal of Computational Linguistics}, 
   note={presented in {CICLING2010}},
   Volume ={1},
   Number ={1-2}, 
   pages = {307--315},
   year={2010},
   url = "http://10.255.0.115/pub/2010/DA10"
}

@InProceedings{lrec10:bigorna,
  author = {José João Almeida, André Santos and Alberto Simões},
  title = {Bigorna -- A Toolkit for Orthography Migration Challenges},
  booktitle = {Proceedings of the Seventh conference on International Language
Resources and Evaluation (LREC'10)},
  year = {2010},
  month = {may},
  date = {19-21},
  address = {Valletta, Malta},
  editor = {Nicoletta Calzolari and others},
  publisher = {European Language Resources Association (ELRA)},
  isbn = {2-9517408-6-7},
  language = {english}
}

@InProceedings{lrec10:dicaberto,
  author = {Alberto Simões, José João Almeida and Rita Farinha},
  title = {Processing and Extracting Data from Dicionário Aberto},
  booktitle = {Proceedings of the Seventh conference on International Language
Resources and Evaluation (LREC'10)},
  year = {2010},
  month = {may},
  date = {19-21},
  address = {Valletta, Malta},
  editor = {Nicoletta Calzolari and others}, 
  publisher = {European Language Resources Association (ELRA)},
  isbn = {2-9517408-6-7},
  language = {english}
 }

@InProceedings{bucc2010,
  author =       {José João Almeida and Alberto Simões},
  title =        {Automatic Parallel Corpora and Bilingual Terminology extraction from Parallel WebSites },
  booktitle =    {BUCC2010 -- 3rd Workshop on Building and Using Comparable Corpora, lrec2010},
  pages =        {50--55},
  year =         {2010},
  editor =       {Reinhard Rapp and Pierre Zweigenbaum and Serge Sharoff},
  address =      {Valletta, Malta},
  month =        {May},
  lang =         {EN},
  abstract = { In our days, the notion, the importance and the
                  significance of parallel corpora is so big that needs
                  no special introduction. Unfortunately, public
                  available parallel corpora is somewhat limited in
                  range. There are big corpora about politics or
                  legislation, about medicine and other specific areas,
                  but we miss corpora for other different
                  areas. Currently there is a huge investment on using
                  the Web as a corpus.  This article uncovers GWB, a
                  tool that aims automatic construction of parallel
                  corpora from the web. We defend that it is possible
                  to build high quality terminological corpora in an
                  automatic fashion, just by specifying a sensible
                  Internet domain and using an appropriate set of seed
                  keywords. GWB is a web-spider that works in
                  conjunction with a set of other Open-Source tools,
                  de¿ning a pipeline that includes the documents
                  retrieval from the web, alignment at sentence level
                  and its quality analysis, bilingual dictionaries and
                  terminology extraction and construction of off-line
                  dictionaries.  }
}

@InProceedings{brett:lrec,
  author =       {José João Almeida and Brett Drury},
  title =        { Identification, extraction and population of collective named
entities from business news},
  booktitle =    {Entity2010 -- Workshop on Resources and Evaluation for Entity Resolution and Entity
Management, lrec2010},
  pages =        {19--22},
  year =         {2010},
  address =      {Valletta, Malta},
  month =        {May},
  lang =         {EN},
  abstract = { 
Sentiment analysis of business news has become an increasingly popular
area of research for both the practitioner and academic. The future
financial prospects of companies can be estimated through the aggregation
of sentiment over a period of time. The aggregation of sentiment
for a specific company is only possible if the company is explicitly
mentioned in the news text. In certain instances, news text may refer
to groups or collections of companies, for example "The Automotive
Sector" or "The Russell Group of Universities".  Widely available named
entity dictionaries will not recognize these groups of companies, and
consequently, it may not be possible to assign sentiment attributed
to these groups of companies to their individual members. This paper
describes a method for identifying groups of companies, which for the
purposes of this paper will be known as "Collective Entities". The
described method is corpus based: it uses linguistic patterns to
identify Collective Entity Names, their members and their natural
relations with other Collective Entities. The described methodology
contains the following steps: 1. Identify and validate seed extraction
patterns, 2. Expand seed patterns, 3. Extract and validate Collective
Named Entities, 4. Extract related Collective Named Entities, 5. Construct
and populate an Ontology and 6. Expand the members of Collective Entity
sets with Linked Data. }
}

@InProceedings{fala2010-triPsi,
 author =       {João Filipe Machado and José João Almeida and Alberto Simões
and Ana Soares},
 title =        {Automating psycholinguistic statistics computation:
Procura-Palavras },
 year =         {2010},
 booktitle =    {FALA2010 -- II Iberian SLTech Workshop},
 editor =       {Carmen Mateo and Francisco Díaz and Francisco Pazó},
 address =      {Vigo},
 pages =        {217--220},
 month =        {November},
 abstract = {
This article describes psycholinguistic lexical databases
available in various languages, including English, Spanish and
Portuguese. These lexical databases are important for researchers 
in Psycholinguistics and other related areas, providing
a pool of experimental materials and allowing for an efficient
process of selection of these experimental materials.
The process of gathering statistics is slow, resulting in a
small pool of materials in the short-term. The need to find an
alternative method to gather limited or yet unavailable statistics
for a specific language led us to consider gathering statistics
from other languages and to compute their triangulation. Our
aim was to automatize the computation of statistics such as 
Familiarity, Imageability, Age of Acquisition and Written Word
Frequency for that specific language.
We will describe the process of preparing this data and triangulating and 
comparing statistics for some languages in an attempt of finding a 
relationship between them. The results were
analysed considering correlations between each statistic in each
pair of languages and by computing the mean of absolute differences between 
each language's values.
 }
}

@article{opencert2010,
  author    = {Alberto Simões and Nuno Carvalho and José João Almeida},
  title     = {Testing as a Certification Approach},
  journal   = {Electronic Communications of the EASST},
  volume    = {33},
  year      = {2010},
  editor    = {Luis Barbosa and Antonio Cerone and Siraj Shaikh (Guest Eds.)},
  note      = {Foundations and Techniques for Open Source Software Certification},
  url       = {http://journal.ub.tu-berlin.de/index.php/eceasst/article/view/458/446}
}



@InProceedings{drury-torgo-almeida:2011:ROBUS,
  author    = {Drury, Brett  and  Torgo, Luis  and  J.J. Almeida},
  title     = {Guided Self Training for Sentiment Classification},
  booktitle = {Proceedings of Workshop on Robust Unsupervised and Semisupervised
Methods in Natural Language Processing},
  month     = {September},
  year      = {2011},
  address   = {Hissar, Bulgaria},
  pages     = {9--16},
  url       = {http://www.aclweb.org/anthology/W11-3902},
}

@inproceedings{drury1,
  title={Classifying News Stories to Estimate the Direction of a Stock Market Index},
  author={Brett Drury and Luis Torgo and J.J. Almeida },
  booktitle={Third Workshop on Intelligent Systems and Applications (WISA)},
  year=2011,
  location = {Chaves},
  pages = {1-4},
}


@inproceedings{drury2,
  title={ Magellan: An Adaptive Ontology Driven "breaking Financial News"
Recommender},
  author={ Brett Drury and  J.J. Almeida and Helena Morais},
  year=2011,
  booktitle = {CISTI-2011},
  location = {Chaves},
}

@inproceedings{drury3,
  title     = {An Error Correction Methodology for Time Dependent Ontologies},
  author={ Brett Drury and  J.J. Almeida and Helena Morais},
  booktitle = {{CAiSE} Workshops (ONTOSE)},
  year      = {2011},
  pages     = {501-512},
  ee        = {http://dx.doi.org/10.1007/978-3-642-22056-2_52},
  editor    = {Camille Salinesi and Oscar Pastor},
  publisher = {Springer},
  series    = {Lecture Notes in Business Information Processing},
  volume    = {83},
  part      = {8},
  isbn      = {978-3-642-22055-5},
}


@inproceedings{nuno1,
  title={ Oml: A Scripting Approach For Manipulating Ontologies},
  author={ Nuno Carvalho and  Alberto Simões and J.J. Almeida},
  booktitle = {CISTI-2011},
  location = {Chaves},
  year=2011,
}

%% Falta publicações no Corta
%% Falta publicações no XATA

@inproceedings{wims2011,
  author    = {Brett Drury and J.J. Almeida},
  title     = {Identification of fine grained feature based event and sentiment
               phrases from business news stories},
  booktitle = {WIMS},
  year      = {2011},
  pages     = {27--34},
  ee        = {http://doi.acm.org/10.1145/1988688.1988720},
  editor    = {Rajendra Akerkar},
  booktitle_full  = {Proceedings of the International Conference on Web
Intelligence, Mining and Semantics, WIMS 2011, Sogndal, Norway, May 25
               - 27, 2011},
  publisher = {ACM},
  isbn      = {978-1-4503-0148-0},
  bibsource = {DBLP, http://dblp.uni-trier.de},
}

@inproceedings{sepln:bookcleaner,
  author={ Santos, André and José João Almeida} ,
  title = {{Text::Perfide::BookCleaner}, a Perl module to
clean and normalize plain text books}, 
  booktitle = {Actas del XXVII Congreso de la Sociedad Española
para el Procesamiento del Lenguaje Natural},
  year= 2011,
  pp={433-441},
  location = {Huelva, 5 - 7 Set},
  url ={http://natura.di.uminho.pt/~jj/pln/sepln2011-boolcleaner.pdf},
}

@article{drury4,
  title={Maintenance of a Fuzzy Temporal Ontology from News Stories},
  author={ Brett Drury and  J.J. Almeida and Helena Morais},
  journal={International Journal of Metadata, Semantics and Ontologies},
  year=2012,
  note={forthcomming},
}

@article{drury5,
  author={ Brett Drury and Luis Torgo and  J.J. Almeida},
  title     = {Classifying News Stories with a Constrained Learning Strategy
               to Estimate the Direction of a Market Index},
  journal_full={International Journal of Computer Science and Applications},
  journal   = {IJCSA},
  volume    = {9},
  number    = {1},
  year      = {2012},
  pages     = {1-22},
  url       = {http://www.tmrfindia.org/ijcsa/v9i11.pdf},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@article{da2012,
  title = {Dicionário-Aberto -- A Source of Resources for the
Portuguese Language Processing},
  author = {Alberto Simões and Álvaro Iriarte Sanromán and José João Almeida},
  year = 2012,
  volume = {7243},
  editor = {Helena Caseli and Aline Villavicencio and António Teixeira
and Fernando Perdigão},
  address = {Coimbra, Portugal},
  pages = {121--127},
  publisher = {Springer},
  month = {April},
  journal = {Computational Processing of the Portuguese Language, Lecture Notes for Artificial Intelligence},
}


@InProceedings{LREC12.967,
  author = {André Santos and José João Almeida and Nuno Carvalho},
  title = {Structural alignment of plain text books},
  booktitle = {Proceedings of the Eight International Conference on Language
Resources and Evaluation (LREC'12)},
  year = {2012},
  month = {may},
  date = {23-25},
  address = {Istanbul, Turkey},
  editor = {Nicoletta Calzolari and others}, 
  publisher = {European Language Resources Association (ELRA)},
  isbn = {978-2-9517408-7-7},
  language = {english}
 }

@InProceedings{LREC12.611,
  author = {Brett Drury and José João Almeida},
  title = {The Minho Quotation Resource},
  booktitle = {Proceedings of the Eight International Conference on Language
Resources and Evaluation (LREC'12)},
  year = {2012},
  month = {may},
  date = {23-25},
  address = {Istanbul, Turkey},
  editor = {Nicoletta Calzolari and others}, 
  publisher = {European Language Resources Association (ELRA)},
  isbn = {978-2-9517408-7-7},
  language = {english}
 }

@InProceedings{CAPH12a,
  author =    {Nuno Ramos Carvalho and Jose Joao Almeida and Maria
João Varanda Pereira and Pedro Rangel Henriques},
  title =     {Probabilistic SynSet Based Concept Location},
  booktitle = {SLATe'12 --- Symposium on Languages, Applications and Technologies},
  editor = {Alberto Simões and Ricardo Queirós and Daniela da Cruz},
  publisher = {OASIC -- Open Access Series in Informatics, Schloss
Dagstuhl - Leibniz-Zentrum für Informatik, Dagstuhl Publishing, Germany},
  year =     {2012},
  month =     {June},
  volume = {21},
  pages     = {239-253},
  ISSN      = {978-3-939879-40-8},
  DOI       = {10.4320/OASIcs.SLATE.2012.I}
}


@article{wikiscore,
  title={{Wiki::Score} A collaborative environment for music transcription and publishing},
  author={J.J. Almeida and Nuno Ramos Carvalho and José Nuno Oliveira},
  journal_small={ISU},
  journal={Information, Services and Use},
  volume={31},
  number={3-4/2011},
  year={2012},
  pages={177--187},
  ee={DOI	10.3233/ISU-2012-0647},
  publisher={IOS Press},
  ISSN={0167-5265 (Print) 1875-8789 (Online)},
  comment={elpub 2012},
}
